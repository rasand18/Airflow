apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: spark-app-{{ params.spark_app_name }}
  namespace: spark-operator
spec:
  type: Python
  mode: cluster
  image: harbor.ad.spendrups.se/dataplatform-test/spark-kafka-to-base:1.0
  imagePullPolicy: Always
  mainApplicationFile: local:///app/sparkKafkaToBase.py
  arguments:
    - "--input_tables"
    - "{{ params.table_name }}"
  sparkVersion: 3.5.3
  timeToLiveSeconds: 600
  sparkConf:
    "spark.yunikorn.queue": "root.{{ params.queue_name | default('low') }}"
    "spark.jars.packages": "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,io.delta:delta-spark_2.12:3.1.0,org.apache.spark:spark-avro_2.12:3.5.1,org.apache.hadoop:hadoop-aws:3.3.1,com.amazonaws:aws-java-sdk-bundle:1.12.375"
    "spark.sql.extensions": "io.delta.sql.DeltaSparkSessionExtension"
    "spark.sql.catalog.spark_catalog": "org.apache.spark.sql.delta.catalog.DeltaCatalog"
    "spark.hadoop.fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
    "spark.hadoop.fs.s3a.aws.credentials.provider": "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider"
    "spark.sql.files.maxPartitionBytes": "134217728"
    "spark.hadoop.fs.s3a.multipart.size: 52428800"  # 50 MB per multipart
    "spark.hadoop.fs.s3a.multipart.threshold: 52428800"  # Vid 50 MB börjar multipart användas
    "spark.hadoop.fs.s3a.block.size: 67108864"  # 64 MB blockstorlek

  driver:
    labels:
      version: 3.5.3
    cores: {{ params.driver_cores | default(1, true) | int }}
    memory: "{{ params.driver_memory | default('1G', true) }}"
    serviceAccount: spark-operator-spark
    env:
      - name: SPARK_YUNIKORN_QUEUE
        value: "root.{{ params.queue_name | default('low', true) }}"
      - name: SPARK_CONF_DIR
        value: "/opt/bitnami/spark/conf"
  executor:
    labels:
      version: 3.5.3
    instances: {{ params.executor_instances | default(1, true) | int }}
    cores: {{ params.executor_cores | default(1, true) | int }}
    memory: "{{ params.executor_memory | default('1G', true) }}"
    env:
      - name: SPARK_YUNIKORN_QUEUE
        value: "root.{{ params.queue_name | default('low', true) }}"
      - name: SPARK_CONF_DIR
        value: "/opt/bitnami/spark/conf"
  batchScheduler: yunikorn
  batchSchedulerOptions:
    queue: "root.{{ params.queue_name | default('low', true) }}"

